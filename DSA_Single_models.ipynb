{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9860014,
          "sourceType": "datasetVersion",
          "datasetId": 6051226
        },
        {
          "sourceId": 176023,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 149863,
          "modelId": 172370
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "DSA_Single_models",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeep-4469/Chexpert_solution/blob/main/DSA_Single_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "u33iE-26rZct"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "sandeep4469_chexpert_path = kagglehub.dataset_download('sandeep4469/chexpert')\n",
        "sandeep4469_atelectasis_best_fine_tuned_model_pytorch_default_1_path = kagglehub.model_download('sandeep4469/atelectasis_best_fine_tuned_model/PyTorch/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "UD1DYXpzrZcu"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "train_dir = '/kaggle/input/chexpert/Dataset/train'\n",
        "valid_dir = '/kaggle/input/chexpert/Dataset/valid'\n",
        "output_dir = '/kaggle/working'\n",
        "\n",
        "diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural_Effusion', 'Pneumonia']\n",
        "\n",
        "def create_new_structure(output_dir, diseases):\n",
        "    for disease in diseases:\n",
        "        # Create new disease folder structure in the output directory\n",
        "        disease_folder = os.path.join(output_dir, f\"{disease}_\")\n",
        "        os.makedirs(os.path.join(disease_folder, 'train', f'{disease}'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(disease_folder, 'train', 'no_finding'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(disease_folder, 'valid', f'{disease}'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(disease_folder, 'valid', 'no_finding'), exist_ok=True)\n",
        "\n",
        "        disease_train_path = os.path.join(train_dir, disease)\n",
        "        if os.path.exists(disease_train_path):\n",
        "            for file_name in os.listdir(disease_train_path):\n",
        "                src = os.path.join(disease_train_path, file_name)\n",
        "                dst = os.path.join(disease_folder, 'train', f'{disease}', file_name)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "        disease_valid_path = os.path.join(valid_dir, disease)\n",
        "        if os.path.exists(disease_valid_path):\n",
        "            for file_name in os.listdir(disease_valid_path):\n",
        "                src = os.path.join(disease_valid_path, file_name)\n",
        "                dst = os.path.join(disease_folder, 'valid', f'{disease}', file_name)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "        # Copy 'No_Finding' images into 'no_finding'\n",
        "        no_finding_train_path = os.path.join(train_dir, 'No_Finding')\n",
        "        if os.path.exists(no_finding_train_path):\n",
        "            for file_name in os.listdir(no_finding_train_path):\n",
        "                src = os.path.join(no_finding_train_path, file_name)\n",
        "                dst = os.path.join(disease_folder, 'train', 'no_finding', file_name)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "        no_finding_valid_path = os.path.join(valid_dir, 'No_Finding')\n",
        "        if os.path.exists(no_finding_valid_path):\n",
        "            for file_name in os.listdir(no_finding_valid_path):\n",
        "                src = os.path.join(no_finding_valid_path, file_name)\n",
        "                dst = os.path.join(disease_folder, 'valid', 'no_finding', file_name)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "create_new_structure(output_dir, diseases)\n",
        "\n",
        "print(\"New folder structure created successfully.\")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T10:15:36.356263Z",
          "iopub.execute_input": "2024-11-23T10:15:36.356927Z",
          "iopub.status.idle": "2024-11-23T10:37:22.315966Z",
          "shell.execute_reply.started": "2024-11-23T10:15:36.356891Z",
          "shell.execute_reply": "2024-11-23T10:37:22.315015Z"
        },
        "id": "ArTM8WHvrZcv",
        "outputId": "f4bf0d6c-1dd2-4842-98d6-7202584c4b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "New folder structure created successfully.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths to directories and other configurations\n",
        "output_dir = '/kaggle/working/chexpert_reorganized'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Define data augmentation and preprocessing\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# List of diseases\n",
        "diseases = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural_Effusion', 'Pneumonia']\n",
        "fine_tuned_models = []\n",
        "\n",
        "# Loop through each disease\n",
        "for disease in diseases:\n",
        "    disease_train_dir = f'/kaggle/working/{disease}_/train'\n",
        "    disease_valid_dir = f'/kaggle/working/{disease}_/valid'\n",
        "\n",
        "    if not os.path.exists(disease_train_dir) or not os.path.exists(disease_valid_dir):\n",
        "        print(f\"Data for {disease} not found in the expected directory structure.\")\n",
        "        continue\n",
        "\n",
        "    # Create train and validation datasets and dataloaders\n",
        "    train_dataset = ImageFolder(disease_train_dir, transform=train_transforms)\n",
        "    valid_dataset = ImageFolder(disease_valid_dir, transform=valid_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Model setup with DenseNet and additional layers\n",
        "    base_model = models.densenet121(pretrained=True)\n",
        "    for param in list(base_model.parameters())[:-5]:\n",
        "        param.requires_grad = False  # Freeze all except the last 5 layers\n",
        "\n",
        "    # Modify the last layers of DenseNet121 model\n",
        "    num_features = base_model.classifier.in_features\n",
        "    base_model.classifier = nn.Sequential(\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    base_model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(base_model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_val_accuracy = 0.0  # Track the best validation accuracy\n",
        "    best_model = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        base_model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{epochs}\", ncols=100) as t:\n",
        "            for inputs, labels in t:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = base_model(inputs)\n",
        "                loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                preds = (outputs > 0.5).float()\n",
        "                correct += (preds == labels.unsqueeze(1)).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                t.set_postfix(loss=running_loss / (t.n + 1), accuracy=100 * correct / total)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = correct / total * 100\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "        # Validation\n",
        "        base_model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with tqdm(valid_loader, desc=f\"Validating Epoch {epoch + 1}/{epochs}\", ncols=100) as t:\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in t:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = base_model(inputs)\n",
        "                    loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    preds = (outputs > 0.5).float()\n",
        "                    correct += (preds == labels.unsqueeze(1)).sum().item()\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                    t.set_postfix(loss=val_loss / (t.n + 1), accuracy=100 * correct / total)\n",
        "\n",
        "        val_loss /= len(valid_loader)\n",
        "        val_accuracy = correct / total * 100\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Update the best model if validation accuracy improves\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_model = base_model.state_dict()\n",
        "\n",
        "    # Save the best model for the current disease\n",
        "    model_path = os.path.join(output_dir, f\"{disease}_best_fine_tuned_model.pth\")\n",
        "    torch.save(best_model, model_path)\n",
        "    print(f\"Best fine-tuned model for {disease} saved successfully at {model_path}.\")\n",
        "\n",
        "    # Store the best model in the list\n",
        "    fine_tuned_models.append(best_model)\n",
        "\n",
        "print(\"All best models have been fine-tuned and saved.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T15:44:28.857484Z",
          "iopub.execute_input": "2024-11-11T15:44:28.858157Z",
          "iopub.status.idle": "2024-11-11T17:11:54.457331Z",
          "shell.execute_reply.started": "2024-11-11T15:44:28.858114Z",
          "shell.execute_reply": "2024-11-11T17:11:54.456146Z"
        },
        "id": "bV4CZ_MvrZcw",
        "outputId": "74887a65-0058-4797-b687-f42e2dac07be"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.29it/s, accuracy=68.9, loss=0.585]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.5854, Accuracy: 68.91%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 4/4 [00:00<00:00,  6.67it/s, accuracy=85.6, loss=0.404]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4040, Validation Accuracy: 85.59%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.24it/s, accuracy=71.1, loss=0.565]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.5652, Accuracy: 71.09%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|███████████████| 4/4 [00:00<00:00,  6.63it/s, accuracy=79.7, loss=0.427]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4269, Validation Accuracy: 79.66%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.26it/s, accuracy=71.5, loss=0.559]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.5591, Accuracy: 71.52%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|███████████████| 4/4 [00:00<00:00,  6.56it/s, accuracy=83.1, loss=0.436]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4363, Validation Accuracy: 83.05%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.28it/s, accuracy=71.8, loss=0.556]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.5560, Accuracy: 71.77%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 4/4 [00:00<00:00,  5.15it/s, accuracy=83.9, loss=0.394]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3936, Validation Accuracy: 83.90%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|████████████| 1250/1250 [01:34<00:00, 13.26it/s, accuracy=72.1, loss=0.55]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.5502, Accuracy: 72.08%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|███████████████| 4/4 [00:00<00:00,  6.45it/s, accuracy=82.2, loss=0.389]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3888, Validation Accuracy: 82.20%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.24it/s, accuracy=72.1, loss=0.549]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.5493, Accuracy: 72.12%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|███████████████| 4/4 [00:00<00:00,  6.25it/s, accuracy=79.7, loss=0.462]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4623, Validation Accuracy: 79.66%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=72.3, loss=0.545]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.5452, Accuracy: 72.31%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|███████████████| 4/4 [00:00<00:00,  6.54it/s, accuracy=82.2, loss=0.368]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3682, Validation Accuracy: 82.20%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=72.6, loss=0.547]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.5466, Accuracy: 72.57%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|███████████████| 4/4 [00:00<00:00,  6.37it/s, accuracy=83.9, loss=0.427]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4274, Validation Accuracy: 83.90%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=72.6, loss=0.544]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.5439, Accuracy: 72.64%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|███████████████| 4/4 [00:00<00:00,  6.73it/s, accuracy=81.4, loss=0.429]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4293, Validation Accuracy: 81.36%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|████████████| 1250/1250 [01:34<00:00, 13.28it/s, accuracy=73, loss=0.541]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.5401, Accuracy: 72.99%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|██████████████| 4/4 [00:00<00:00,  6.14it/s, accuracy=79.7, loss=0.395]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3954, Validation Accuracy: 79.66%\nBest fine-tuned model for Atelectasis saved successfully at /kaggle/working/chexpert_reorganized/Atelectasis_best_fine_tuned_model.pth.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.27it/s, accuracy=72.4, loss=0.548]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.5478, Accuracy: 72.44%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 4/4 [00:00<00:00,  6.85it/s, accuracy=81.1, loss=0.434]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4338, Validation Accuracy: 81.13%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.26it/s, accuracy=74.1, loss=0.524]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.5244, Accuracy: 74.11%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|███████████████| 4/4 [00:00<00:00,  7.06it/s, accuracy=76.4, loss=0.461]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4609, Validation Accuracy: 76.42%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=75.2, loss=0.514]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.5140, Accuracy: 75.17%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|███████████████| 4/4 [00:00<00:00,  7.11it/s, accuracy=74.5, loss=0.485]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4852, Validation Accuracy: 74.53%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|████████████| 1250/1250 [01:34<00:00, 13.27it/s, accuracy=75.4, loss=0.51]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.5100, Accuracy: 75.38%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 4/4 [00:00<00:00,  6.84it/s, accuracy=75.5, loss=0.457]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4570, Validation Accuracy: 75.47%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=75.7, loss=0.507]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.5071, Accuracy: 75.66%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|███████████████| 4/4 [00:00<00:00,  7.47it/s, accuracy=74.5, loss=0.506]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.5059, Validation Accuracy: 74.53%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|███████████| 1250/1250 [01:33<00:00, 13.41it/s, accuracy=75.7, loss=0.506]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.5064, Accuracy: 75.65%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|█████████████████| 4/4 [00:00<00:00,  7.02it/s, accuracy=84, loss=0.415]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4150, Validation Accuracy: 83.96%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|███████████| 1250/1250 [01:33<00:00, 13.37it/s, accuracy=76.1, loss=0.501]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.5011, Accuracy: 76.14%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|███████████████| 4/4 [00:00<00:00,  6.82it/s, accuracy=75.5, loss=0.486]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4859, Validation Accuracy: 75.47%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|███████████| 1250/1250 [01:33<00:00, 13.40it/s, accuracy=76.4, loss=0.497]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.4972, Accuracy: 76.41%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|███████████████| 4/4 [00:00<00:00,  6.89it/s, accuracy=80.2, loss=0.418]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4181, Validation Accuracy: 80.19%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|███████████| 1250/1250 [01:33<00:00, 13.38it/s, accuracy=76.6, loss=0.497]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.4968, Accuracy: 76.59%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|███████████████| 4/4 [00:00<00:00,  5.96it/s, accuracy=75.5, loss=0.476]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4763, Validation Accuracy: 75.47%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|██████████| 1250/1250 [01:34<00:00, 13.21it/s, accuracy=76.8, loss=0.494]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.4942, Accuracy: 76.76%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|██████████████| 4/4 [00:00<00:00,  7.18it/s, accuracy=81.1, loss=0.431]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4310, Validation Accuracy: 81.13%\nBest fine-tuned model for Cardiomegaly saved successfully at /kaggle/working/chexpert_reorganized/Cardiomegaly_best_fine_tuned_model.pth.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|███████████| 1087/1087 [01:22<00:00, 13.21it/s, accuracy=74.1, loss=0.526]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.5253, Accuracy: 74.14%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 3/3 [00:00<00:00,  6.47it/s, accuracy=94.4, loss=0.444]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2961, Validation Accuracy: 94.37%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|█████████████| 1087/1087 [01:21<00:00, 13.28it/s, accuracy=76, loss=0.502]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.5019, Accuracy: 76.03%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|████████████████| 3/3 [00:00<00:00,  6.53it/s, accuracy=94.4, loss=0.44]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2936, Validation Accuracy: 94.37%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|███████████| 1087/1087 [01:21<00:00, 13.33it/s, accuracy=76.6, loss=0.493]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.4925, Accuracy: 76.63%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|███████████████| 3/3 [00:00<00:00,  6.41it/s, accuracy=91.5, loss=0.366]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2438, Validation Accuracy: 91.55%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|███████████| 1087/1087 [01:21<00:00, 13.29it/s, accuracy=76.9, loss=0.491]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.4901, Accuracy: 76.93%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 3/3 [00:00<00:00,  6.63it/s, accuracy=91.5, loss=0.409]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2725, Validation Accuracy: 91.55%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|███████████| 1087/1087 [01:21<00:00, 13.29it/s, accuracy=77.1, loss=0.483]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.4833, Accuracy: 77.10%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|███████████████| 3/3 [00:00<00:00,  6.26it/s, accuracy=88.7, loss=0.403]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2686, Validation Accuracy: 88.73%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|████████████| 1087/1087 [01:21<00:00, 13.28it/s, accuracy=77.8, loss=0.48]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.4791, Accuracy: 77.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|███████████████| 3/3 [00:00<00:00,  6.37it/s, accuracy=88.7, loss=0.382]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2548, Validation Accuracy: 88.73%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|███████████| 1087/1087 [01:21<00:00, 13.29it/s, accuracy=77.7, loss=0.478]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.4778, Accuracy: 77.67%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|███████████████| 3/3 [00:00<00:00,  6.40it/s, accuracy=91.5, loss=0.364]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2427, Validation Accuracy: 91.55%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|█████████████| 1087/1087 [01:22<00:00, 13.23it/s, accuracy=78, loss=0.476]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.4758, Accuracy: 77.97%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|███████████████| 3/3 [00:00<00:00,  6.39it/s, accuracy=94.4, loss=0.359]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2395, Validation Accuracy: 94.37%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|█████████████| 1087/1087 [01:21<00:00, 13.31it/s, accuracy=78, loss=0.471]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.4710, Accuracy: 78.04%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|███████████████| 3/3 [00:00<00:00,  6.18it/s, accuracy=90.1, loss=0.402]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2681, Validation Accuracy: 90.14%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|██████████| 1087/1087 [01:22<00:00, 13.24it/s, accuracy=77.9, loss=0.474]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.4745, Accuracy: 77.89%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|██████████████| 3/3 [00:00<00:00,  6.73it/s, accuracy=87.3, loss=0.351]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2341, Validation Accuracy: 87.32%\nBest fine-tuned model for Consolidation saved successfully at /kaggle/working/chexpert_reorganized/Consolidation_best_fine_tuned_model.pth.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.28it/s, accuracy=77.6, loss=0.474]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.4733, Accuracy: 77.61%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 3/3 [00:00<00:00,  6.21it/s, accuracy=86.7, loss=0.476]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3176, Validation Accuracy: 86.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=79.4, loss=0.446]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.4455, Accuracy: 79.41%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|█████████████████| 3/3 [00:00<00:00,  5.72it/s, accuracy=88, loss=0.464]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3091, Validation Accuracy: 87.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=80.1, loss=0.435]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.4351, Accuracy: 80.09%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|█████████████████| 3/3 [00:00<00:00,  5.66it/s, accuracy=88, loss=0.381]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2542, Validation Accuracy: 87.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.20it/s, accuracy=80.2, loss=0.434]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.4337, Accuracy: 80.23%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 3/3 [00:00<00:00,  6.38it/s, accuracy=86.7, loss=0.469]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3124, Validation Accuracy: 86.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|███████████| 1250/1250 [01:35<00:00, 13.15it/s, accuracy=80.6, loss=0.428]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.4281, Accuracy: 80.58%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|████████████████| 3/3 [00:00<00:00,  5.95it/s, accuracy=86.7, loss=0.45]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3002, Validation Accuracy: 86.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|█████████████| 1250/1250 [01:34<00:00, 13.16it/s, accuracy=81, loss=0.422]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.4224, Accuracy: 80.99%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|███████████████| 3/3 [00:00<00:00,  5.98it/s, accuracy=86.7, loss=0.478]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3190, Validation Accuracy: 86.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|██████████████| 1250/1250 [01:34<00:00, 13.26it/s, accuracy=81, loss=0.42]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.4202, Accuracy: 81.04%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|█████████████████| 3/3 [00:00<00:00,  5.26it/s, accuracy=88, loss=0.463]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3084, Validation Accuracy: 87.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.23it/s, accuracy=81.4, loss=0.414]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.4141, Accuracy: 81.38%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|█████████████████| 3/3 [00:00<00:00,  5.83it/s, accuracy=88, loss=0.406]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2708, Validation Accuracy: 87.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.19it/s, accuracy=81.4, loss=0.415]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.4152, Accuracy: 81.41%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|███████████████| 3/3 [00:00<00:00,  5.43it/s, accuracy=86.7, loss=0.406]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2705, Validation Accuracy: 86.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|██████████| 1250/1250 [01:34<00:00, 13.19it/s, accuracy=81.4, loss=0.415]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.4149, Accuracy: 81.44%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|██████████████| 3/3 [00:00<00:00,  5.67it/s, accuracy=92.8, loss=0.385]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2570, Validation Accuracy: 92.77%\nBest fine-tuned model for Edema saved successfully at /kaggle/working/chexpert_reorganized/Edema_best_fine_tuned_model.pth.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.17it/s, accuracy=73.3, loss=0.535]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.5350, Accuracy: 73.34%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 4/4 [00:00<00:00,  6.81it/s, accuracy=77.1, loss=0.418]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4178, Validation Accuracy: 77.14%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|████████████| 1250/1250 [01:34<00:00, 13.23it/s, accuracy=75.4, loss=0.51]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.5100, Accuracy: 75.37%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|████████████████| 4/4 [00:00<00:00,  6.83it/s, accuracy=82.9, loss=0.42]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4201, Validation Accuracy: 82.86%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=76.2, loss=0.498]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.4981, Accuracy: 76.19%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|█████████████████| 4/4 [00:00<00:00,  7.30it/s, accuracy=81, loss=0.394]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3938, Validation Accuracy: 80.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.24it/s, accuracy=76.7, loss=0.491]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.4914, Accuracy: 76.71%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 4/4 [00:00<00:00,  7.20it/s, accuracy=76.2, loss=0.404]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4038, Validation Accuracy: 76.19%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|█████████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=77, loss=0.489]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.4891, Accuracy: 76.99%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|███████████████| 4/4 [00:00<00:00,  6.87it/s, accuracy=85.7, loss=0.398]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3981, Validation Accuracy: 85.71%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.21it/s, accuracy=77.3, loss=0.484]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.4843, Accuracy: 77.28%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|███████████████| 4/4 [00:00<00:00,  6.75it/s, accuracy=84.8, loss=0.373]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3728, Validation Accuracy: 84.76%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=77.5, loss=0.482]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.4820, Accuracy: 77.53%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|███████████████| 4/4 [00:00<00:00,  7.01it/s, accuracy=83.8, loss=0.378]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3782, Validation Accuracy: 83.81%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.22it/s, accuracy=77.7, loss=0.477]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.4764, Accuracy: 77.72%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|███████████████| 4/4 [00:00<00:00,  6.74it/s, accuracy=81.9, loss=0.394]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3937, Validation Accuracy: 81.90%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|███████████| 1250/1250 [01:34<00:00, 13.25it/s, accuracy=77.8, loss=0.475]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.4747, Accuracy: 77.84%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|█████████████████| 4/4 [00:00<00:00,  6.90it/s, accuracy=83.8, loss=0.4]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4005, Validation Accuracy: 83.81%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|██████████| 1250/1250 [01:33<00:00, 13.30it/s, accuracy=77.9, loss=0.475]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.4742, Accuracy: 77.90%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|███████████████| 4/4 [00:00<00:00,  7.45it/s, accuracy=82.9, loss=0.41]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.4104, Validation Accuracy: 82.86%\nBest fine-tuned model for Pleural_Effusion saved successfully at /kaggle/working/chexpert_reorganized/Pleural_Effusion_best_fine_tuned_model.pth.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 1/10: 100%|█████████████| 814/814 [01:01<00:00, 13.18it/s, accuracy=78.7, loss=0.483]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [1/10], Loss: 0.4833, Accuracy: 78.71%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 1/10: 100%|███████████████| 2/2 [00:00<00:00,  5.06it/s, accuracy=93.5, loss=0.245]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2455, Validation Accuracy: 93.48%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 2/10: 100%|█████████████| 814/814 [01:01<00:00, 13.18it/s, accuracy=79.4, loss=0.464]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [2/10], Loss: 0.4641, Accuracy: 79.45%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 2/10: 100%|███████████████| 2/2 [00:00<00:00,  4.98it/s, accuracy=93.5, loss=0.218]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2181, Validation Accuracy: 93.48%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 3/10: 100%|█████████████| 814/814 [01:01<00:00, 13.25it/s, accuracy=79.7, loss=0.461]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [3/10], Loss: 0.4600, Accuracy: 79.75%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 3/10: 100%|███████████████| 2/2 [00:00<00:00,  4.59it/s, accuracy=93.5, loss=0.187]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.1871, Validation Accuracy: 93.48%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 4/10: 100%|█████████████| 814/814 [01:01<00:00, 13.28it/s, accuracy=79.9, loss=0.459]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [4/10], Loss: 0.4586, Accuracy: 79.89%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 4/10: 100%|███████████████| 2/2 [00:00<00:00,  5.21it/s, accuracy=91.3, loss=0.239]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2390, Validation Accuracy: 91.30%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 5/10: 100%|█████████████| 814/814 [01:01<00:00, 13.13it/s, accuracy=79.7, loss=0.456]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [5/10], Loss: 0.4556, Accuracy: 79.72%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 5/10: 100%|███████████████| 2/2 [00:00<00:00,  5.25it/s, accuracy=89.1, loss=0.216]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2162, Validation Accuracy: 89.13%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 6/10: 100%|█████████████| 814/814 [01:01<00:00, 13.16it/s, accuracy=79.9, loss=0.453]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [6/10], Loss: 0.4533, Accuracy: 79.95%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 6/10: 100%|███████████████| 2/2 [00:00<00:00,  5.06it/s, accuracy=91.3, loss=0.204]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2043, Validation Accuracy: 91.30%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 7/10: 100%|█████████████| 814/814 [01:01<00:00, 13.15it/s, accuracy=79.9, loss=0.451]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [7/10], Loss: 0.4509, Accuracy: 79.88%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 7/10: 100%|███████████████| 2/2 [00:00<00:00,  5.04it/s, accuracy=95.7, loss=0.213]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.2134, Validation Accuracy: 95.65%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 8/10: 100%|█████████████| 814/814 [01:01<00:00, 13.17it/s, accuracy=80.1, loss=0.449]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [8/10], Loss: 0.4493, Accuracy: 80.08%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 8/10: 100%|███████████████| 2/2 [00:00<00:00,  5.11it/s, accuracy=95.7, loss=0.192]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.1921, Validation Accuracy: 95.65%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 9/10: 100%|███████████████| 814/814 [01:01<00:00, 13.20it/s, accuracy=80, loss=0.453]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [9/10], Loss: 0.4528, Accuracy: 80.04%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 9/10: 100%|███████████████| 2/2 [00:00<00:00,  5.10it/s, accuracy=91.3, loss=0.309]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.3092, Validation Accuracy: 91.30%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training Epoch 10/10: 100%|████████████| 814/814 [01:01<00:00, 13.17it/s, accuracy=80.3, loss=0.446]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch [10/10], Loss: 0.4460, Accuracy: 80.34%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Validating Epoch 10/10: 100%|██████████████| 2/2 [00:00<00:00,  5.14it/s, accuracy=95.7, loss=0.178]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Validation Loss: 0.1782, Validation Accuracy: 95.65%\nBest fine-tuned model for Pneumonia saved successfully at /kaggle/working/chexpert_reorganized/Pneumonia_best_fine_tuned_model.pth.\nAll best models have been fine-tuned and saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Path to saved models and validation images\n",
        "output_dir = '/kaggle/working/chexpert_reorganized'  # Directory where models are saved\n",
        "disease_valid_dirs = {\n",
        "    'Atelectasis': '/kaggle/input/chexpert/Dataset/train/No_Finding',\n",
        "    'Cardiomegaly': '/kaggle/input/chexpert/Dataset/valid/Cardiomegaly',\n",
        "    'Consolidation': '/kaggle/input/chexpert/Dataset/valid/Consolidation',\n",
        "    'Edema': '/kaggle/input/chexpert/Dataset/valid/Edema',\n",
        "    'Pleural_Effusion': '/kaggle/input/chexpert/Dataset/valid/Pleural_Effusion',\n",
        "    'Pneumonia': '/kaggle/input/chexpert/Dataset/valid/Pneumonia'\n",
        "}\n",
        "\n",
        "# Transform for validation images\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loop through each disease\n",
        "for disease, valid_dir in disease_valid_dirs.items():\n",
        "    # Update the model path to match the correct filename pattern\n",
        "    model_path = os.path.join(output_dir, f\"{disease}_best_fine_tuned_model.pth\")\n",
        "\n",
        "    # Initialize DenseNet121 model\n",
        "    base_model = models.densenet121(pretrained=True)\n",
        "    for param in list(base_model.parameters())[:-5]:\n",
        "        param.requires_grad = False  # Freeze all except the last 5 layers\n",
        "\n",
        "    # Modify the classifier layer\n",
        "    num_features = base_model.classifier.in_features\n",
        "    base_model.classifier = nn.Sequential(\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    # Load model weights and move to device\n",
        "    base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    base_model.to(device)\n",
        "    base_model.eval()\n",
        "\n",
        "    # List files in the validation directory, filtering out directories\n",
        "    image_files = [f for f in os.listdir(valid_dir) if os.path.isfile(os.path.join(valid_dir, f))]\n",
        "    if not image_files:\n",
        "        print(f\"No images found in {valid_dir}\")\n",
        "        continue\n",
        "\n",
        "    # Loop to process only the first image\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        if i >= 1:\n",
        "            break  # Stop after processing the first image only\n",
        "\n",
        "        image_path = os.path.join(valid_dir, image_file)\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = valid_transforms(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            output = base_model(image)\n",
        "            probability = output.item()\n",
        "            prediction = \"Positive\" if probability > 0.5 else \"Negative\"\n",
        "\n",
        "        print(f\"{disease} - First image: {image_file} - Prediction: {prediction} - Probability: {probability:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T17:56:14.485202Z",
          "iopub.execute_input": "2024-11-11T17:56:14.485905Z",
          "iopub.status.idle": "2024-11-11T17:56:25.801593Z",
          "shell.execute_reply.started": "2024-11-11T17:56:14.485862Z",
          "shell.execute_reply": "2024-11-11T17:56:25.800615Z"
        },
        "id": "IhaHNF56rZcw",
        "outputId": "7b89a565-6a22-49a9-b20c-6cff4c23033f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/2936342642.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Atelectasis - First image: patient14030_study5_view1_frontal.jpg - Prediction: Positive - Probability: 0.6232\nCardiomegaly - First image: patient64624_study1_view1_frontal.jpg - Prediction: Negative - Probability: 0.2684\nConsolidation - First image: patient64624_study1_view1_frontal.jpg - Prediction: Negative - Probability: 0.3180\nEdema - First image: patient64563_study1_view1_frontal.jpg - Prediction: Negative - Probability: 0.4270\nPleural_Effusion - First image: patient64644_study1_view1_frontal.jpg - Prediction: Negative - Probability: 0.0834\nPneumonia - First image: patient64692_study1_view1_frontal.jpg - Prediction: Negative - Probability: 0.3825\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "/kaggle/working/chexpert_reorganized/Pneumonia_best_fine_tuned_model.pth"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T15:33:25.826808Z",
          "iopub.execute_input": "2024-11-11T15:33:25.827204Z",
          "iopub.status.idle": "2024-11-11T15:33:26.856327Z",
          "shell.execute_reply.started": "2024-11-11T15:33:25.827167Z",
          "shell.execute_reply": "2024-11-11T15:33:26.855166Z"
        },
        "id": "s4RW4tcnrZcx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_dir = '/kaggle/working/chexpert_reorganized'\n",
        "print(\"Files in output_dir:\", os.listdir(output_dir))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T17:45:47.054032Z",
          "iopub.execute_input": "2024-11-11T17:45:47.054915Z",
          "iopub.status.idle": "2024-11-11T17:45:47.060058Z",
          "shell.execute_reply.started": "2024-11-11T17:45:47.054875Z",
          "shell.execute_reply": "2024-11-11T17:45:47.059096Z"
        },
        "id": "fnvjhR9CrZcx",
        "outputId": "99631249-d59d-445f-cad2-a347ce98b6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Files in output_dir: ['Consolidation_best_fine_tuned_model.pth', 'Pleural_Effusion_best_fine_tuned_model.pth', 'Atelectasis_best_fine_tuned_model.pth', 'Pneumonia_best_fine_tuned_model.pth', 'Cardiomegaly_best_fine_tuned_model.pth', 'Edema_best_fine_tuned_model.pth']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.classes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T18:01:12.006794Z",
          "iopub.execute_input": "2024-11-11T18:01:12.007174Z",
          "iopub.status.idle": "2024-11-11T18:01:12.014335Z",
          "shell.execute_reply.started": "2024-11-11T18:01:12.00714Z",
          "shell.execute_reply": "2024-11-11T18:01:12.013477Z"
        },
        "id": "-yql2GsXrZcx",
        "outputId": "54c4fb60-4071-4391-ea46-52fd4a2e8422"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Pneumonia', 'no_finding']"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Path to the directory where models are saved\n",
        "output_dir = '/kaggle/working/chexpert_reorganized'\n",
        "\n",
        "# Path to the zip file you want to create\n",
        "zip_file_path = '/kaggle/working/fine_tuned_models.zip'\n",
        "\n",
        "# Create a zip file containing all .pth files in the output directory\n",
        "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith('.pth'):\n",
        "            model_file = os.path.join(output_dir, filename)\n",
        "            zipf.write(model_file, os.path.basename(model_file))  # Add the model file to the zip\n",
        "\n",
        "print(f\"All .pth files have been zipped and saved to {zip_file_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-11T18:03:42.566603Z",
          "iopub.execute_input": "2024-11-11T18:03:42.56728Z",
          "iopub.status.idle": "2024-11-11T18:03:43.025585Z",
          "shell.execute_reply.started": "2024-11-11T18:03:42.567238Z",
          "shell.execute_reply": "2024-11-11T18:03:43.024662Z"
        },
        "id": "4C_xQh27rZcx",
        "outputId": "67de55ba-b604-40e4-9a5d-132898eeb3a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "All .pth files have been zipped and saved to /kaggle/working/fine_tuned_models.zip\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "results = []\n",
        "for disease in diseases:\n",
        "    # Set paths for train and validation\n",
        "    train_path = os.path.join(output_dir, f\"{disease}_\", \"train\")\n",
        "    valid_path = os.path.join(output_dir, f\"{disease}_\", \"valid\")\n",
        "\n",
        "    # Use ImageFolder to load datasets\n",
        "    valid_dataset = ImageFolder(valid_path, transform=transform)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Class mapping (0 = no_finding, 1 = disease)\n",
        "    class_mapping = {v: k for k, v in valid_dataset.class_to_idx.items()}\n",
        "    print(f\"{disease} class mapping: {class_mapping}\")\n",
        "\n",
        "    # Load model\n",
        "    model_path = f\"/kaggle/input/atelectasis_best_fine_tuned_model/pytorch/default/1/{disease}_best_fine_tuned_model.pth\"\n",
        "    base_model = models.densenet121(pretrained=True)\n",
        "    for param in list(base_model.parameters())[:-5]:\n",
        "        param.requires_grad = False\n",
        "\n",
        "    num_features = base_model.classifier.in_features\n",
        "    base_model.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Linear(num_features, 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(0.3),\n",
        "        torch.nn.Linear(512, 1),\n",
        "        torch.nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    base_model.to(device)\n",
        "    base_model.eval()\n",
        "\n",
        "    # Evaluate model on validation data\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = base_model(images)\n",
        "            preds = (outputs > 0.5).float().squeeze(1)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        \"Disease\": disease,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    })\n",
        "\n",
        "# Create a DataFrame with results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T10:38:00.507281Z",
          "iopub.execute_input": "2024-11-23T10:38:00.507638Z",
          "iopub.status.idle": "2024-11-23T10:38:15.207908Z",
          "shell.execute_reply.started": "2024-11-23T10:38:00.507608Z",
          "shell.execute_reply": "2024-11-23T10:38:15.206823Z"
        },
        "id": "OPuWkmxSrZcy",
        "outputId": "0925e7ea-b2ae-4839-f818-23319283f6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Atelectasis class mapping: {0: 'Atelectasis', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 149MB/s] \n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Cardiomegaly class mapping: {0: 'Cardiomegaly', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Consolidation class mapping: {0: 'Consolidation', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Edema class mapping: {0: 'Edema', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Pleural_Effusion class mapping: {0: 'Pleural_Effusion', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Pneumonia class mapping: {0: 'Pneumonia', 1: 'no_finding'}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/tmp/ipykernel_30/2759566442.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  base_model.load_state_dict(torch.load(model_path, map_location=device))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "            Disease  Accuracy  Precision    Recall  F1 Score\n0       Atelectasis  0.796610   0.634615  0.868421  0.733333\n1      Cardiomegaly  0.811321   0.680000  0.894737  0.772727\n2     Consolidation  0.873239   0.808511  1.000000  0.894118\n3             Edema  0.927711   0.863636  1.000000  0.926829\n4  Pleural_Effusion  0.828571   0.738095  0.815789  0.775000\n5         Pneumonia  0.956522   0.950000  1.000000  0.974359\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "yb2Ne_71rZcy"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}